{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, val, and test sets. In addition we will\n",
    "# create a small development set as a subset of the training data;\n",
    "# we can use this for development so our code runs faster.\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 500\n",
    "\n",
    "# Our validation set will be num_validation points from the original\n",
    "# training set.\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "\n",
    "# Our training set will be the first num_train points from the original\n",
    "# training set.\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# We will also make a development set, which is a small subset of\n",
    "# the training set.\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "# We use the first num_test points of the original test set as our\n",
    "# test set.\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (49000, 3072)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Test data shape:  (1000, 3072)\n",
      "dev data shape:  (500, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.64189796 135.98173469 132.47391837 130.05569388 135.34804082\n",
      " 131.75402041 130.96055102 136.14328571 132.47636735 131.48467347]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing: subtract the mean image\n",
    "# first: compute the image mean based on the training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "print(mean_image[:10])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((32,32,3)).astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second: subtract the mean image from train and test data\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 3073) (1000, 3073) (1000, 3073) (500, 3073)\n"
     ]
    }
   ],
   "source": [
    "# third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
    "# only has to worry about optimizing a single weight matrix W.\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 9.191088\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers.linear_svm import svm_loss_naive\n",
    "import time\n",
    "\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "print('loss: %f' % (loss, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsdf = np.zeros((5,4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09943298, -0.3037261 ,  0.66422534, -0.63560279,  0.1001941 ,\n",
       "       -0.33011667,  0.14974327, -0.48257891,  0.45436539,  0.1609235 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev[3].dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3073)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
